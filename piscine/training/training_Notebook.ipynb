{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5472fcde-ef87-4dfa-a7b1-fffb70b48079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn imports for machine learning\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocessing and pipeline utilities\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Model imports\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Metrics and model evaluation\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, r2_score, \\\n",
    "                            mean_absolute_error, f1_score, precision_score, \\\n",
    "                            recall_score, roc_auc_score, confusion_matrix, \\\n",
    "                            roc_curve, auc\n",
    "\n",
    "# Additional utilities\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa05174-1d95-4d26-99e1-b748254f97cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 1: MSE Scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cffa76e-145b-4b3d-98ad-d1316650fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [91, 51, 2.5, 2, -5]\n",
    "y_pred = [90, 48, 2, 2, -4]\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be0cc7a-3225-4d07-be54-8d5cb035a940",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 2: Accuracy Scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee0bc3-4c0d-4f6c-b8dd-4a5ae6843358",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [0, 1, 0, 1, 0, 1, 0]\n",
    "y_true = [0, 0, 1, 1, 1, 1, 0]\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_true)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd2d12-de5c-4d86-889d-d6ff8aabc55f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 3: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5025c6-1c73-4b13-a96a-9122b5dbfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "# data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "# split data train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=13)\n",
    "# pipeline\n",
    "pipeline = [('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lr', LinearRegression())]\n",
    "\n",
    "\n",
    "pipe = Pipeline(pipeline)\n",
    "# fit\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predictions on training set\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "# Predictions on test set\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Predicted Train:\", y_train_pred[:10])\n",
    "print(\"\")\n",
    "print(\"Predicted Test:\", y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c40af-0b4c-42e7-992f-1677a1c7ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Compute metrics for test set\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"R2 Train:\", r2_train)\n",
    "print(\"MSE Train:\", mse_train)\n",
    "print(\"MAE Train:\", mae_train)\n",
    "print(\"\")\n",
    "print(\"R2 Test:\", r2_test)\n",
    "print(\"MSE Test:\", mse_test)\n",
    "print(\"MAE Test:\", mae_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d574c-d572-479c-af85-b32806ebcb9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 4: Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def94639-065a-441b-a0de-87dc80205085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Load the breast cancer dataset\n",
    "X , y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "#Split the data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=43)\n",
    "\n",
    "#Standardize the data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Fit the scaler to the training data and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "#Fit the classifier to the scaled training data\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c71e3-b553-4983-ae41-0e8bc8736bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classifier.predict(X_train_scaled)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "print(\"Predicted Train:\", y_train_pred[:10])\n",
    "print(\"\")\n",
    "print(\"Predicted Test:\", y_test_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b8350-8b05-496a-8b09-447152a5b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute metrics for the training set\n",
    "print(\"Training Set Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, y_train_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_train, y_train_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_train, y_train_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_train, y_train_pred)}\")\n",
    "\n",
    "# Compute AUC on the training set - need to use predict_proba to get probabilities\n",
    "y_train_proba = classifier.predict_proba(X_train_scaled)[:, 1]  # Probabilities of the positive class\n",
    "print(f\"ROC AUC: {roc_auc_score(y_train, y_train_proba)}\")\n",
    "\n",
    "# Compute metrics for the test set\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_test_pred)}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_test_pred)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_test_pred)}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_test_pred)}\")\n",
    "\n",
    "# Compute AUC on the test set - need to use predict_proba to get probabilities\n",
    "y_test_proba = classifier.predict_proba(X_test_scaled)[:, 1]  # Probabilities of the positive class\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba)}\")\n",
    "\n",
    "# Print the confusion matrix for the test set\n",
    "print(\"\\nConfusion Matrix for the Test Set:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4136e-5628-4575-849f-191ed148184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Generate the plot\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='blue', lw=lw, label='Pipeline (AUC = %0.2f)' % roc_auc)\n",
    "padding = 0.02  # This is the padding value. Adjust it to add more or less padding.\n",
    "plt.xlim([0.0 - padding, 1.0 + padding])\n",
    "plt.ylim([0.0 - padding, 1.05 + padding])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c872e8-e9da-448a-a663-fff4514ab565",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 5: Machine Learning models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0661a42-e540-48d0-bf85-613eb0d574a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Train R^2: 0.6054131599242079\n",
      "Test R^2: 0.6128959462132961\n",
      "Train MSE: 0.5273648371379568\n",
      "Test MSE: 0.49761195027083827\n",
      "Train MAE: 0.5330920012614553\n",
      "Test MAE: 0.5196420310323718\n",
      "----------------------------------------\n",
      "SVM:\n",
      "Train R^2: 0.7496108582936591\n",
      "Test R^2: 0.7295080649899655\n",
      "Train MSE: 0.3346447867133981\n",
      "Test MSE: 0.3477101776543043\n",
      "Train MAE: 0.3835645163325976\n",
      "Test MAE: 0.3897680598426732\n",
      "----------------------------------------\n",
      "Decision Tree:\n",
      "Train R^2: 1.0\n",
      "Test R^2: 0.6411350449487532\n",
      "Train MSE: 9.287461238793889e-32\n",
      "Test MSE: 0.4613113410207364\n",
      "Train MAE: 4.212344895326283e-17\n",
      "Test MAE: 0.4339228100775194\n",
      "----------------------------------------\n",
      "Random Forest:\n",
      "Train R^2: 0.9741424383160557\n",
      "Test R^2: 0.8127465331519781\n",
      "Train MSE: 0.034558600088180014\n",
      "Test MSE: 0.24070934396507854\n",
      "Train MAE: 0.11989028276808825\n",
      "Test MAE: 0.31935835024224823\n",
      "----------------------------------------\n",
      "Gradient Boosting:\n",
      "Train R^2: 0.8042086499063386\n",
      "Test R^2: 0.7895081234643192\n",
      "Train MSE: 0.26167490389525294\n",
      "Test MSE: 0.27058170064218096\n",
      "Train MAE: 0.35656543036682264\n",
      "Test MAE: 0.36455447680396397\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fetching the dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=43)\n",
    "\n",
    "# Preprocessing steps remain constant\n",
    "preprocessing_steps = [('imputer', SimpleImputer(strategy='median')),\n",
    "                       ('scaler', StandardScaler())]\n",
    "\n",
    "# Models to be tested\n",
    "models = [\n",
    "    ('Linear Regression', LinearRegression()),\n",
    "    ('SVM', SVR()),\n",
    "    ('Decision Tree', DecisionTreeRegressor(random_state=43)),\n",
    "    ('Random Forest', RandomForestRegressor(random_state=43)),\n",
    "    ('Gradient Boosting', GradientBoostingRegressor(random_state=43))\n",
    "]\n",
    "\n",
    "for name, model in models:\n",
    "    pipeline = Pipeline(preprocessing_steps + [(name, model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Calculating metrics\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Train R^2: {metrics.r2_score(y_train, y_train_pred)}\")\n",
    "    print(f\"Test R^2: {metrics.r2_score(y_test, y_test_pred)}\")\n",
    "    print(f\"Train MSE: {metrics.mean_squared_error(y_train, y_train_pred)}\")\n",
    "    print(f\"Test MSE: {metrics.mean_squared_error(y_test, y_test_pred)}\")\n",
    "    print(f\"Train MAE: {metrics.mean_absolute_error(y_train, y_train_pred)}\")\n",
    "    print(f\"Test MAE: {metrics.mean_absolute_error(y_test, y_test_pred)}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    #R2 is how well the X features are to the y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286f557-2d80-466d-9d62-2d592d9b9c09",
   "metadata": {},
   "source": [
    "## Exercise 6: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735fb6ad-e055-4216-9a8e-d642a51203cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "Best estimator: RandomForestRegressor(max_depth=7, min_samples_leaf=10, n_estimators=75)\n",
      "Best parameters: {'max_depth': 7, 'min_samples_leaf': 10, 'n_estimators': 75}\n",
      "Best score: 0.6303702349922858\n",
      "[CV] END ..max_depth=3, min_samples_leaf=30, n_estimators=50; total time=   1.5s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=20, n_estimators=75; total time=   3.4s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=10, n_estimators=10; total time=   0.3s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=30, n_estimators=75; total time=   2.1s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=10, n_estimators=50; total time=   3.0s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=20, n_estimators=75; total time=   2.3s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=30, n_estimators=75; total time=   3.2s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=10, n_estimators=50; total time=   1.5s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=20, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=30, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=10, n_estimators=10; total time=   0.6s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=20, n_estimators=10; total time=   0.6s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=20, n_estimators=50; total time=   2.8s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=30, n_estimators=10; total time=   0.3s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=50; total time=   2.3s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=10, n_estimators=75; total time=   4.2s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=10, n_estimators=75; total time=   2.2s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=30, n_estimators=50; total time=   2.2s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=30, n_estimators=50; total time=   2.6s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=20, n_estimators=50; total time=   1.5s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=20, n_estimators=50; total time=   2.3s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=20, n_estimators=75; total time=   3.9s\n",
      "[CV] END ..max_depth=3, min_samples_leaf=20, n_estimators=10; total time=   0.3s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=10; total time=   0.5s\n",
      "[CV] END ..max_depth=5, min_samples_leaf=10, n_estimators=75; total time=   3.3s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=30, n_estimators=10; total time=   0.6s\n",
      "[CV] END ..max_depth=7, min_samples_leaf=30, n_estimators=75; total time=   3.5s\n"
     ]
    }
   ],
   "source": [
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "# Define the parameter grid\n",
    "parameters = {'n_estimators':[10, 50, 75],\n",
    "            'max_depth':[3,5,7],\n",
    "            'min_samples_leaf': [10,20,30]}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "gridsearch = GridSearchCV(rf,\n",
    "                        parameters,\n",
    "                        cv = [(np.arange(18576), np.arange(18576,20640))],\n",
    "                        n_jobs=-1,\n",
    "                        verbose=2\n",
    "                        )\n",
    "gridsearch.fit(X, y)\n",
    "\n",
    "\n",
    "print(\"Best estimator:\", gridsearch.best_estimator_)\n",
    "print(\"Best parameters:\", gridsearch.best_params_)\n",
    "print(\"Best score:\", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df933a1-bf22-4037-ada0-949729a7cde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(RandomForestRegressor(max_depth=7, min_samples_leaf=20, n_estimators=75), {'max_depth': 7, 'min_samples_leaf': 20, 'n_estimators': 75}, 0.6254436458009907)\n"
     ]
    }
   ],
   "source": [
    "def select_model_verbose(gs):\n",
    "    return gs.best_estimator_, gs.best_params_, gs.best_score_\n",
    "\n",
    "print(select_model_verbose(gridsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808a9098-74a6-4ea4-a650-33eaaa8b9819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.58939561])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, best_params, best_score = select_model_verbose(gridsearch)\n",
    "\n",
    "new_point = np.array([[3.2031, 52., 5.47761194, 1.07960199, 910., 2.26368159, 37.85, -122.26]])\n",
    "\n",
    "model.predict(new_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f8c17-f1cc-4616-9772-4ff52743e41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
